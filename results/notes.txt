initial fitness .01
fintess reduction .1
check action  set subsumption
prediction error reduction is 1 instead of .25 as in the paper

still open question:
why the fitness of classifiers with zero TP can be highest?
wrong action: reward 0 , prediction 0 , accuracy high, fitness high?

Investigation required:
Why the accuracy is either 1 or less than .09?

todo:
- implement don't care/ masking for filters (should get generic filters)
- implement different types of filters (different sizes, with don't care values, dilated filters)
- why tournament selection is using fitness/numerosity? Try to understand the function
- implement GP crossover
- think about filter composition / layering
- implement crossover at three levels (classifier, code fragment, filter) and mutation at 2 levels (code fragment and filter)
