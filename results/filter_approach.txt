Asslam o Alaikum Dr. Iqbal and Dr Irfan,

I have been working on devising possible strategies for performing image classification using classifier system.

Adapting the c++ code (RCFC) provided by Dr. Iqbal I have done some experiments using a new representation for classifier code_fragment which I call "filter" approach.

The classifier code_fragment is now represented as a 2d filter (e.g. 4x4) in my current experiments. The filter consists of same lower and upper bound of real numbers. The idea is to extract useful features from images automatically for classification purposes.
 
An input image matches a filter using the following mechanism

- Starting from top left corner the 2d filter is matched with the corresponding area of the input image. If the image pixels matches with the filter it is included in the match set. It is a similar mechanism of sliding filter as found in a CNN.

In this way we hope to evolve useful features describing image characteristics that can be used for classification. The same filters can also be used for transfer learning scenarios.

I have executed experiments for classification of digits 3 and 8 of MNIST digit dataset using this approach. The transfer learning experiments are not done yet. Following are the main modifications done in the original RCFC code:

1. The code_fragment now consists of only one 4x4 filter (The operator AND is used to ensure that all pixels of a particular region match the filter)
2. Covering is done more aggressively initially which means that the new filters are produced from the input images as long as the total numbers of classifiers are less than maxPopSize/2
3. New mutation implementation is done for mutating individual alleles of the filters
4. New crossover implementation is also done for crossover of two filters
5. For subsumption the code was only checking for equality which is now changed to checking of generality.

Following are the results of the best experiment so far

Parameters:
N=2000
Training set size: ~11k images
Epochs=6 (~70k training images presented) 
Test Frequency = 1000

Maximum training accuracy = 95.7%
Test accuracy = 95%
Total time taken for execution: 403 minutes

Accuracy and error graphs are attached below


My observations:

- It was difficult to surpass the barrier of 90% accuracy 
- Ideally we should be able to reach 99% with this simple problem of MNIST digits
- The time complexity of the filter method is quite high.
- Good news is that we are able to reach reasonable accuracy while directly working on pixel level without using auto encoder.
- The code fragment approach reached 90% and the filter approach is able to reach 95% accuracy
- Still need to explore further strategies to increase the representation power of the method
- Need to explore
	- Hierarchical filters or composition of filters to be explored
	- Filters of Multiple sizes (e.g. 3x3, 5x5 etc.) and their combinations 
	- A filter might match multiple times in an image. Need to account for that
	- An effective covering strategy is to be devised
	- Multiple filters within the code_fragment of a classifiers just like multiple code fragments
	- Current approach has the characteristic of location invariance (a feature can occur anywhere in the image for filter to detect it)
	- Work on size and rotation invariance strategies 
	- work on increasing time efficiency of the algorithm


I need your guidance for proceeding further. Do you think this result is good enough for our first publication on "Image classification using classifier systems". We have only worked on 2 digits yet. Classification of 10 digits might require transfer learning. MNIST itself is a toy problem but we do not have a precedence of solving it effectively with evolutionary methods before which makes it significant? 
Our next avenue is to work on transfer learning. 

Thank you very much.



Generalization of rules:
Total Training Images: 11982
Class 0 images (digit 3): 6131
Class 1 images (digit 8): 5851

Total rules 877 (sum of numerosity = N = 2000)
Average fitness 0.05
Number of rules above average fitness: 272 (sum of numerosity = 1066

Following are some observations about the rules:
- Top 10 rules with highest fitness (from .51 to .30) have two kinds of rules.
a. All rules have low prediction error
b. There are 6 rules with with prediction value 0. Also they only match the images of opposite class (zero true positives). I think it is because these rules only appear in action set when the random action selected is opposite to that of actual class of the image.
c. 4 rules have high prediction (almost equal to max prediction value) but they have very low true positive (close to or less than 1% only). 

- If we look at the rules with highest true positive (from 42% to 21%) we wee
a. Rules have low prediction error
a. Rules have highest prediction (close to 1000)
b. However the fitness is low (between .05 and .18)

 Question is what kinds of rules are better, the  ones with high fitness but low true positive or with high true positive but low fitness.

Please let me know if further analysis is to be done about the rules 

I have shared the working sheet with you if you  want to see all the attributes of the rules. 



#20 May

Next steps...

The XOF paper (with observed list of CFs) pointed out by Dr. Irfan has interesting insights.

I am planing to implement following now:

1. Implement filters at leaf nodes. At the moment the filters represent the complete code fragment. By implementing filters at the leaf node we can combine various filters in the code fragment to create high level features.
2. Implement different sizes (e.g. 3x3 or 5x5) and types of filters (e.g. normal filters, filters with don't care values, dilated filters)
3. Implement observed list of filters and/or CFs to reduce search space as suggested in the XOF paper.

I might have to rewrite much of the existing code base for this purpose. Will be looking at the best way to structure the code.


#14 Jun

Asslam o Alaikum,

I have completed implementation for following:
- Filters at leaf level
- Managed list of filters similar to the "observed list"

I have not yet implemented different types of filters.

Following are the observations from experiments:

- The results of the experiments for 2 digits are similar with validation accuracy reaching 95.4% and training accuracy 96.5%. This accuracy is reached without using code fragments (tree depth=0) which means one filter per classifier
- It seems the  using code fragments (tree depth = 2) there is not much improvement in case of 2 digits
- The results for 4 digit classification are 78.6% validation and 80% training
- The results improved slightly when using code fragments (tree depth = 2), 81.1% validation and 82% training

Next steps could be:
- implement different types of filters
- reuse "promising" filters from 2 digit training in 4 digit classification.

So far we can see that filter + code fragments are still not able to take us to 99% accuracy for 2 digits that I feel we should theoretically reach. I am not sure what we might be missing. 

Should we go ahead to at least publish the new filter approach with current results while we explore transfer learning direction?


@Dr. Irfan the special issue that you shared is related to deep learning. How do you think we can participate in that with our current direction?

  
